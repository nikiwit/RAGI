# ===============================================================
# RAGI Configuration Template
# ===============================================================
# Copy this file to .env and customize for your environment
# All settings are optional - defaults will be used if not specified

# ===============================================================
# CORE SETTINGS
# ===============================================================

# Environment (local/production)
RAGI_ENV=local

# Paths - Customize these to match your setup
RAGI_DATA_PATH=./data
RAGI_VECTOR_PATH=./vector_store

# ===============================================================
# MODEL CONFIGURATION
# ===============================================================

# Embedding Model - Used for converting text to vectors
# Options: BAAI/bge-base-en-v1.5 (default), BAAI/bge-large-en-v1.5 (better quality, slower)
RAGI_EMBEDDING_MODEL=BAAI/bge-base-en-v1.5

# LLM Model - Ollama model for response generation
# Options: qwen2.5:3b-instruct (default), llama2, mistral, etc.
RAGI_LLM_MODEL=qwen2.5:3b-instruct

# Reranker Model - Used to improve search result relevance
# Options: BAAI/bge-reranker-base (default), BAAI/bge-reranker-large (better, slower)
RAGI_RERANKER_MODEL=BAAI/bge-reranker-base

# ===============================================================
# CHROMADB OPTIMIZATION
# ===============================================================
# Disable ChromaDB telemetry for privacy and reduced noise

ANONYMIZED_TELEMETRY=False
CHROMA_TELEMETRY_DISABLED=1

# ===============================================================
# HUGGINGFACE OPTIMIZATION
# ===============================================================
# These settings significantly reduce startup time and noise

HF_HUB_DISABLE_TELEMETRY=1
HF_HUB_DISABLE_PROGRESS_BARS=1
HF_HUB_DISABLE_SYMLINKS_WARNING=1
HF_HOME=./model_cache/huggingface
TRANSFORMERS_VERBOSITY=error
TOKENIZERS_PARALLELISM=false

# ===============================================================
# DOCUMENT PROCESSING
# ===============================================================

# Chunk Size - Number of characters per document chunk
# Smaller = more precise retrieval, Larger = more context per chunk
RAGI_CHUNK_SIZE=500

# Chunk Overlap - Character overlap between chunks
# Helps maintain context across chunk boundaries
RAGI_CHUNK_OVERLAP=150

# Document Filtering - Process all files or only knowledge base files
# Set to false to process ALL files in data folder (RECOMMENDED - processes everything)
# Set to true to filter for specific KB patterns (advanced use only)
RAGI_FILTER_KB_ONLY=false

# Optional: Content type filtering (comma-separated, e.g., "policy,guide,manual")
# Leave empty to process all content types
RAGI_KB_CONTENT_TYPES=

# ===============================================================
# OCR (OPTICAL CHARACTER RECOGNITION) SETTINGS
# ===============================================================

# Enable OCR for extracting text from images in PDFs
# Set to true to enable OCR (requires Tesseract installation)
RAGI_USE_OCR=true

# Use PyMuPDF for advanced PDF processing (recommended)
# PyMuPDF provides better layout preservation and faster processing
RAGI_USE_PYMUPDF=true

# OCR Language - use ISO 639-2 language codes
# Common: eng (English), spa (Spanish), fra (French), deu (German), chi_sim (Chinese Simplified)
# For multiple languages: eng+fra+spa
RAGI_OCR_LANGUAGE=eng

# OCR DPI - Resolution for image processing (higher = better quality but slower)
# 300 is recommended for most documents, 150 for faster processing
RAGI_OCR_DPI=300

# Minimum text threshold - If a PDF page has fewer than this many characters,
# OCR will be triggered (intelligent detection)
RAGI_OCR_MIN_TEXT_THRESHOLD=50

# PDF Layout Preservation - Maintain document structure for better LLM understanding
RAGI_PDF_PRESERVE_LAYOUT=true

# ===============================================================
# SEARCH & RETRIEVAL
# ===============================================================

# Number of documents to retrieve per query
RAGI_RETRIEVER_K=6

# Search Type: semantic, keyword, or hybrid
# hybrid = combines semantic and keyword search (recommended)
RAGI_SEARCH_TYPE=hybrid

# Keyword Ratio - Weight of keyword search in hybrid mode (0.0-1.0)
# Higher = more weight on keyword matching
RAGI_KEYWORD_RATIO=0.4

# FAQ Match Weight - Boost for FAQ-style matches (0.0-2.0)
RAGI_FAQ_MATCH_WEIGHT=0.5

# FAQ Matching - Enable/disable FAQ matching feature
RAGI_USE_FAQ_MATCHING=true

# Knowledge Base Settings
RAGI_KB_ANSWER_SIZE=3
RAGI_KB_EXACT_MATCH_BOOST=2.0

# ===============================================================
# QUERY PROCESSING
# ===============================================================

# Query Expansion - Expand queries with related terms
RAGI_QUERY_EXPANSION=true
RAGI_EXPANSION_FACTOR=3

# Maximum context size for LLM prompts (in characters)
RAGI_MAX_CONTEXT_SIZE=4000

# Context Compression - Reduce retrieved context to most relevant parts
RAGI_CONTEXT_COMPRESSION=true

# Confidence Threshold - Minimum confidence to provide an answer (0.0-1.0)
# Lower values (0.15) reduce false negatives (rejecting valid answers)
# Higher values (0.4+) reduce false positives (answering with irrelevant info)
RAGI_CONFIDENCE_THRESHOLD=0.15

# ===============================================================
# SEMANTIC ENHANCEMENT (ADVANCED)
# ===============================================================

# Enhanced Semantics - Use spaCy for better semantic understanding
RAGI_USE_ENHANCED_SEMANTICS=true

# spaCy Model - Must be downloaded first (python -m spacy download en_core_web_md)
RAGI_SEMANTIC_MODEL=en_core_web_md

# Semantic Cache Size - Number of semantic analyses to cache
RAGI_SEMANTIC_CACHE_SIZE=1000

# Semantic Expansion Limit - Max number of related terms to add
RAGI_SEMANTIC_EXPANSION_LIMIT=5

# Semantic Error Threshold - Max consecutive errors before disabling
RAGI_SEMANTIC_ERROR_THRESHOLD=5

# ===============================================================
# OLLAMA CONFIGURATION
# ===============================================================

# Ollama API URL - Change if running Ollama on different host/port
RAGI_OLLAMA_URL=http://localhost:11434

# ===============================================================
# LOGGING
# ===============================================================

# Log Level: DEBUG, INFO, WARNING, ERROR, CRITICAL
RAGI_LOG_LEVEL=INFO

# Log Rotation Settings
RAGI_LOG_MAX_BYTES=1073741824        # 1GB per log file
RAGI_LOG_BACKUP_COUNT=5              # Keep 5 backup files (max ~6GB total)
RAGI_LOG_USE_JSON=false              # Use JSON format for structured logging

# ===============================================================
# SUPPORT CONTACT INFORMATION
# ===============================================================

RAGI_SUPPORT_PHONE=+1-xxx-xxx-xxxx
RAGI_SUPPORT_EMAIL=support@example.com
RAGI_SUPPORT_LOCATION=Support Center

# ===============================================================
# RESOURCE LIMITS
# ===============================================================

# Maximum threads for parallel processing
RAGI_MAX_THREADS=4

# Maximum memory allocation
RAGI_MAX_MEMORY=4G

# ===============================================================
# MAINTENANCE & DEBUGGING
# ===============================================================

# Force Reindexing - Rebuild vector store on startup
RAGI_FORCE_REINDEX=false

# ===============================================================
# MODEL MANAGEMENT (LEGACY - FOR BACKWARD COMPATIBILITY)
# ===============================================================
# These settings are kept for compatibility but are not actively used
# in the simplified version of RAGI

RAGI_MODEL_CHECK_INTERVAL_DAYS=7
RAGI_MODEL_WARNING_AGE_DAYS=30
RAGI_MODEL_CRITICAL_AGE_DAYS=90
RAGI_MODEL_AUTO_UPDATE_PROMPT=false
RAGI_MODEL_UPDATE_CHECK_ENABLED=false
RAGI_MODEL_REQUIRE_APPROVAL=true
RAGI_MODEL_CACHE_CLEANUP=false
RAGI_MODEL_BACKUP_ENABLED=false
RAGI_MODEL_MAX_BACKUPS=3
RAGI_MODEL_NOTIFICATION_EMAIL=
